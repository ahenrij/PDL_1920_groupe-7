Dataset Name,Brief description,Preprocessing,Instances,Format,Default Task,Created (updated),Reference,Creator
<<<<<<< HEAD
Visual Genome,Images and their description,,"108,000","images, text",Image captioning,2016,[50],R. Krishna et al.
Berkeley 3-D Object Dataset,849 images taken in 75 different scenes. About 50 different object classes are labeled.,Object bounding boxes and labeling.,849,"labeled images, text",Object recognition,2014,[51][52],A. Janoch et al.
Berkeley Segmentation Data Set and Benchmarks 500 (BSDS500),"500 natural images, explicitly separated into disjoint train, validation and test subsets + benchmarking code. Based on BSDS300.",Each image segmented by five different subjects on average.,500,Segmented images,Contour detection and hierarchical image segmentation,2011,[53],"University of California, Berkeley"
Microsoft Common Objects in Context (COCO),complex everyday scenes of common objects in their natural context.,"Object highlighting, labeling, and classification into 91 object types.","2,500,000","Labeled images, text",Object recognition,2015,[54][55],T. Lin et al.
SUN Database,Very large scene and object recognition database.,Places and objects are labeled. Objects are segmented.,"131,067","Images, text","Object recognition, scene recognition",2014,[56][57],J. Xiao et al.
ImageNet,"Labeled object image database, used in the ImageNet Large Scale Visual Recognition Challenge","Labeled objects, bounding boxes, descriptive words, SIFT features","14,197,122","Images, text","Object recognition, scene recognition",2009 (2014),[58][59][60],J. Deng et al.
Open Images,A Large set of images listed as having CC BY 2.0 license with image-level labels and bounding boxes spanning thousands of classes.,"Image-level labels, Bounding boxes","9,178,275","Images, text","Classification, Object recognition",2017,[61],
TV News Channel Commercial Detection Dataset,TV commercials and news broadcasts.,Audio and video features extracted from still images.,"129,685",Text,"Clustering, classification",2015,[62][63],P. Guha et al.
Statlog (Image Segmentation) Dataset,The instances were drawn randomly from a database of 7 outdoor images and hand-segmented to create a classification for every pixel.,Many features calculated.,2310,Text,Classification,1990,[64],University of Massachusetts
Caltech 101,Pictures of objects.,Detailed object outlines marked.,9146,Images,"Classification, object recognition.",2003,[65][66],F. Li et al.
Caltech-256,Large dataset of images for object classification.,Images categorized and hand-sorted.,"30,607","Images, Text","Classification, object detection",2007,[67][68],G. Griffin et al.
SIFT10M Dataset,SIFT features of Caltech-256 dataset.,Extensive SIFT feature extraction.,"11,164,866",Text,"Classification, object detection",2016,[69],X. Fu et al.
LabelMe,Annotated pictures of scenes.,Objects outlined.,"187,240","Images, text","Classification, object detection",2005,[70],MIT Computer Science and Artificial Intelligence Laboratory
Cityscapes Dataset,"Stereo video sequences recorded in street scenes, with pixel-level annotations. Metadata also included.",Pixel-level segmentation and labeling,"25,000","Images, text","Classification, object detection",2016,[71],Daimler AG et al.
PASCAL VOC Dataset,Large number of images for classification tasks.,"Labeling, bounding box included","500,000","Images, text","Classification, object detection",2010,[72][73],M. Everingham et al.
CIFAR-10 Dataset,"Many small, low-resolution, images of 10 classes of objects.","Classes labelled, training set splits created.","60,000",Images,Classification,2009,[59][74],A. Krizhevsky et al.
CIFAR-100 Dataset,"Like CIFAR-10, above, but 100 classes of objects are given.","Classes labelled, training set splits created.","60,000",Images,Classification,2009,[59][74],A. Krizhevsky et al.
CINIC-10 Dataset,"A unified contribution of CIFAR-10 and Imagenet with 10 classes, and 3 splits. Larger than CIFAR-10.","Classes labelled, training, validation, test set splits created.","270,000",Images,Classification,2018,[75],"Luke N. Darlow, Elliot J. Crowley, Antreas Antoniou, Amos J. Storkey"
Fashion-MNIST,A MNIST-like fashion product database,"Classes labelled, training set splits created.","60,000",Images,Classification,2017,[76],Zalando SE
notMNIST,"Some publicly available fonts and extracted glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J taken from different fonts.","Classes labelled, training set splits created.","500,000",Images,Classification,2011,[77],Yaroslav Bulatov
German Traffic Sign Detection Benchmark Dataset,Images from vehicles of traffic signs on German roads. These signs comply with UN standards and therefore are the same as in other countries.,Signs manually labeled,900,Images,Classification,2013,[78][79],S Houben et al.
KITTI Vision Benchmark Dataset,Autonomous vehicles driving through a mid-size city captured images of various areas using cameras and laser scanners.,Many benchmarks extracted from data.,>100 GB of data,"Images, text","Classification, object detection",2012,[80][81],A Geiger et al.
Linnaeus 5 dataset,Images of 5 classes of objects.,"Classes labelled, training set splits created.",8000,Images,Classification,2017,[82],Chaladze & Kalatozishvili
FieldSAFE,"Multi-modal dataset for obstacle detection in agriculture including stereo camera, thermal camera, web camera, 360-degree camera, lidar, radar, and precise localization.",Classes labelled geographically.,>400 GB of data,Images and 3D point clouds,"Classification, object detection, object localization",2017,[83],M. Kragh et al.
11K Hands,"11,076 hand images (1600 x 1200 pixels) of 190 subjects, of varying ages between 18 – 75 years old, for gender recognition and biometric identification.",None,"11,076 hand images","Images and (.mat, .txt, and .csv) label files",Gender recognition and biometric identification,2017,[84],M Afifi
CORe50,"Specifically designed for Continuous/Lifelong Learning and Object Recognition, is a collection of more than 500 videos (30fps) of 50 domestic objects belonging to 10 different categories.","Classes labelled, training set splits created based on a 3-way, multi-runs benchmark.","164,866 RBG-D images","images (.png or .pkl) and (.pkl, .txt, .tsv) label files","Classification, Object recognition",2017,[85],V. Lomonaco and D. Maltoni
OpenLORIS-Object,"Lifelong/Continual Robotic Vision dataset (OpenLORIS-Object) collected by real robots mounted with multiple high-resolution sensors, includes a collection of 121 object instances (1st version of dataset, 40 categories daily necessities objects under 20 scenes). The dataset has rigorously considered 4 environment factors under different scenes, including illumination, occlusion, object pixel size and clutter, and defines the difficulty levels of each factor explicitly.","Classes labelled, training/validation/testing set splits created by benchmark scripts.","1,106,424 RBG-D images",images (.png and .pkl) and (.pkl) label files,"Classification, Lifelong object recognition, Robotic Vision",2019,[86],Q. She et al.
THz and thermal video data set,"This multispectral data set includes terahertz, thermal, visual, near infrared, and three-dimensional videos of objects hidden under people's clothes.",3D lookup tables are provided that allow you to project images onto 3D point clouds.,More than 20 videos. The duration of each video is about 85 seconds (about 345 frames).,AP2J,Experiments with hidden object detection,2019,[87][88],Alexei A. Morozov and Olga S. Sushkova
=======
Density functional theory quantum simulations of graphene,Labelled images of raw input to a simulation of graphene,Raw data (in HDF5 format) and output labels from density functional theory quantum simulation,60744 test and 501473 and training files,Labeled images,Regression,2019,[125],K. Mills & I. Tamblyn
Quantum simulations of an electron in a two dimensional potential well,Labelled images of raw input to a simulation of 2d Quantum mechanics,Raw data (in HDF5 format) and output labels from quantum simulation,1.3 million images,Labeled images,Regression,2017,[126],"K. Mills, M.A. Spanner, & I. Tamblyn"
MPII Cooking Activities Dataset,Videos and images of various cooking activities.,"Activity paths and directions, labels, fine-grained motion labeling, activity class, still image extraction and labeling.","881,755 frames","Labeled video, images, text",Classification,2012,[127][128],M. Rohrbach et al.
FAMOS Dataset,"5,000 unique microstructures, all samples have been acquired 3 times with two different cameras.","Original PNG files, sorted per camera and then per acquisition. MATLAB datafiles with one 16384 times 5000 matrix per camera per acquisition.","30,000",Images and .mat files,Authentication,2012,[129],"S. Voloshynovskiy, et al."
PharmaPack Dataset,"1,000 unique classes with 54 images per class.","Class labeling, many local descriptors, like SIFT and aKaZE, and local feature agreators, like Fisher Vector (FV).","54,000",Images and .mat files,Fine-grain classification,2017,[130],"O. Taran and S. Rezaeifar, et al."
Stanford Dogs Dataset,Images of 120 breeds of dogs from around the world.,Train/test splits and ImageNet annotations provided.,"20,580","Images, text",Fine-grain classification,2011,[131][132],A. Khosla et al.
StanfordExtra Dataset,2D keypoints and segmentations for the Stanford Dogs Dataset.,2D keypoints and segmentations provided.,"12,035",Labelled images,3D reconstruction/pose estimation,2020,[133],B. Biggs et al.
The Oxford-IIIT Pet Dataset,37 categories of pets with roughly 200 images of each.,"Breed labeled, tight bounding box, foreground-background segmentation.","~ 7,400","Images, text","Classification, object detection",2012,[132][134],O. Parkhi et al.
Corel Image Features Data Set,Database of images with features extracted.,"Many features including color histogram, co-occurrence texture, and colormoments,","68,040",Text,"Classification, object detection",1999,[135][136],M. Ortega-Bindenberger et al.
Online Video Characteristics and Transcoding Time Dataset.,Transcoding times for various different videos and video properties.,Video features given.,"168,286",Text,Regression,2015,[137],T. Deneke et al.
Microsoft Sequential Image Narrative Dataset (SIND),Dataset for sequential vision-to-language,"Descriptive caption and storytelling given for each photo, and photos are arranged in sequences","81,743","Images, text",Visual storytelling,2016,[138],Microsoft Research
Caltech-UCSD Birds-200-2011 Dataset,Large dataset of images of birds.,"Part locations for birds, bounding boxes, 312 binary attributes given","11,788","Images, text",Classification,2011,[139][140],C. Wah et al.
YouTube-8M,Large and diverse labeled video dataset,YouTube video IDs and associated labels from a diverse vocabulary of 4800 visual entities,8 million,"Video, text",Video classification,2016,[141][142],S. Abu-El-Haija et al.
YFCC100M,Large and diverse labeled image and video dataset,"Flickr Videos and Images and associated description, titles, tags, and other metadata (such as EXIF and geotags)",100 million,"Video, Image, Text",Video and Image classification,2016,[143][144],B. Thomee et al.
Discrete LIRIS-ACCEDE,Short videos annotated for valence and arousal.,Valence and arousal labels.,9800,Video,Video emotion elicitation detection,2015,[145],Y. Baveye et al.
Continuous LIRIS-ACCEDE,Long videos annotated for valence and arousal while also collecting Galvanic Skin Response.,Valence and arousal labels.,30,Video,Video emotion elicitation detection,2015,[146],Y. Baveye et al.
MediaEval LIRIS-ACCEDE,Extension of Discrete LIRIS-ACCEDE including annotations for violence levels of the films.,"Violence, valence and arousal labels.",10900,Video,Video emotion elicitation detection,2015,[147],Y. Baveye et al.
Leeds Sports Pose,Articulated human pose annotations in 2000 natural sports images from Flickr.,Rough crop around single person of interest with 14 joint labels,2000,Images plus .mat file labels,Human pose estimation,2010,[148],S. Johnson and M. Everingham
Leeds Sports Pose Extended Training,"Articulated human pose annotations in 10,000 natural sports images from Flickr.",14 joint labels via crowdsourcing,10000,Images plus .mat file labels,Human pose estimation,2011,[149],S. Johnson and M. Everingham
MCQ Dataset,"6 different real multiple choice-based exams (735 answer sheets and 33,540 answer boxes) to evaluate computer vision techniques and systems developed for multiple choice test assessment systems.",None,"735 answer sheets and 33,540 answer boxes",Images and .mat file labels,Development of multiple choice test assessment systems,2017,[150][151],"Afifi, M. et al."
Surveillance Videos,Real surveillance videos cover a large surveillance time (7 days with 24 hours each).,None,19 surveillance videos (7 days with 24 hours each).,Videos,Data compression,2016,[152],"Taj-Eddin, I. A. T. F. et al."
LILA BC,Labeled Information Library of Alexandria: Biology and Conservation. Labeled images that support machine learning research around ecology and environmental science.,None,~10M images,Images,Classification,2019,[153],LILA working group
Can We See Photosynthesis?,32 videos for eight live and eight dead leaves recorded under both DC and AC lighting conditions.,None,32 videos,Videos,Liveness detection of plants,2017,[154],"Taj-Eddin, I. A. T. F. et al."
>>>>>>> ff4582384893868142f1b485861afa33c91d9c67
